{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0502413f",
   "metadata": {},
   "source": [
    "This Jupyter notebook should provide a quick overview of the dataset and its files.\n",
    "The ideal setup would be to load the data for the project over to AWS S3 buckets, while this notebook runs on a AWS EMR cluster.\n",
    "\n",
    "The notebook will show as well some assumptions used on the different datasets to later perform some QA.\n",
    "\n",
    "Let begin with some basic settings and imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db37388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType, StringType, TimestampType, \\\n",
    "    StructType, StructField, DoubleType, LongType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97f372",
   "metadata": {},
   "source": [
    "Initializa Spark session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3cc619",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee0a9a",
   "metadata": {},
   "source": [
    "The following sections defines the files addresses in the repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60ed1c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = '../data'\n",
    "customerlogins_file = os.path.join(input_data, 'customerlogins.csv')\n",
    "customerregistration_files = os.path.join(input_data, 'customerregistration*.csv')\n",
    "instantgames_file = os.path.join(input_data, 'instantgamespurchases.csv')\n",
    "lotterygames_file = os.path.join(input_data, 'lotterygamespurchases.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c12b0",
   "metadata": {},
   "source": [
    "### Customer login data overview:\n",
    "\n",
    "Import the data and show the first 10 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff7971ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(customerlogins_file, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a3131b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------+\n",
      "|           timestamp|    site|customernumber|\n",
      "+--------------------+--------+--------------+\n",
      "|2018-05-04 16:51:...|websiteF|        565560|\n",
      "|2020-01-29 09:17:...|websiteZ|        566115|\n",
      "|2019-02-16 02:20:...|websiteX|        564512|\n",
      "|2019-04-11 18:36:...|websiteZ|        565588|\n",
      "|2018-06-07 13:47:...|websiteE|        565823|\n",
      "|2019-11-07 06:47:...|websiteX|        565719|\n",
      "|2019-05-25 02:55:...|websiteB|        565672|\n",
      "|2020-01-09 14:18:...|websiteF|        566021|\n",
      "|2018-06-02 06:55:...|websiteZ|        565540|\n",
      "|2019-05-18 21:28:...|websiteG|        565659|\n",
      "+--------------------+--------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80831da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (9515715, 3)\n",
      "Records with empty timestamp value: 0\n",
      "Records with empty site value: 100043\n",
      "Records with empty customernumber value: 100395\n",
      "Records with digits inside site: 0\n",
      "Records with literals inside customernumber: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataframe shape: ({df.count()}, {len(df.columns)})\")\n",
    "print(f\"Records with empty timestamp value: {df.where(col('timestamp').isNull()).count()}\")\n",
    "print(f\"Records with empty site value: {df.where(col('site').isNull()).count()}\")\n",
    "print(f\"Records with empty customernumber value: {df.where(col('customernumber').isNull()).count()}\")\n",
    "print(f\"Records with digits inside site: {df.select('site').distinct().where(col('site').rlike('^[0-9]*$')).count()}\")\n",
    "print(f\"Records with literals inside customernumber: {df.select('customernumber').distinct().where(~col('customernumber').rlike('^[0-9]*$')).count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0454f5e",
   "metadata": {},
   "source": [
    "### Customer registration data overview:\n",
    "\n",
    "Import the data and show the first 10 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df8f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(customerregistration_files, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28fb6cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+----------------+----------------+--------------------------+--------------------+---------------------------+-------------------------+-----------------------------+---------------------+--------------------+--------------+\n",
      "|           timestamp|    site|       customeremail|         dateofbirth|      familyname|      givennames|primaryaddress_addressline| primaryaddress_city|primaryaddress_federalstate|primaryaddress_postalcode|primaryaddress_sovereignstate|primaryaddress_street|    registrationdate|customernumber|\n",
      "+--------------------+--------+--------------------+--------------------+----------------+----------------+--------------------------+--------------------+---------------------------+-------------------------+-----------------------------+---------------------+--------------------+--------------+\n",
      "|2018-06-01 23:01:...|websiteH|phjiwbc15@ifcgiu.net|1983-05-17 18:26:...|Jonathon Daniels|     Betsy Hogan|      97 East Nobel Avenue| 52 Rocky Hague Road|                   Illinois|                    91053|                     Kentucky| 65 White First Fr...|2018-06-01 23:01:...|        294506|\n",
      "|2018-06-01 23:01:...|websiteG|ousaxb.kghjsx@wge...|1993-03-21 15:40:...|  Calvin Sellers|      Kerry Paul|      17 West White Oak...|827 East White Fa...|                       null|                    25622|                West Virginia|      10 Cowley Drive|2018-06-01 23:01:...|        874009|\n",
      "|2018-06-01 23:05:...|websiteH|   oqyg32@glhces.com|1984-08-28 18:36:...|    Paula Potter|   Cameron Terry|              46 Hague Way|708 Rocky Old Street|               North Dakota|                    63762|                       Hawaii| 33 South Rocky Co...|2018-06-01 23:05:...|        760672|\n",
      "|2018-06-01 23:06:...|websiteC|gdtzze5@wdll.cdds...|1985-01-05 14:18:...|     Gerald Bush|            null|       952 White Hague Way|    69 Fabien Avenue|                   Colorado|                     6533|                        Idaho|                 null|2018-06-01 23:06:...|        494712|\n",
      "|2018-06-01 23:07:...|websiteD|trsxdmjj.btnaaaoe...|1992-01-17 14:47:...| Cassandra Potts|    Antoine Bean|      651 Green Cowley ...|92 White Cowley B...|                     Nevada|                    94398|                     Missouri| 71 South Green Fa...|2018-06-01 23:07:...|        610451|\n",
      "|2018-06-01 23:07:...|websiteA|inus.oeefruehg@ym...|1986-07-26 05:51:...|  Nicholas Booth|    Ramon Conley|       780 White Nobel Way|     848 Milton Road|                   Michigan|                    26642|                 Rhode Island|     97 West Old Road|2018-06-01 23:07:...|        110144|\n",
      "|2018-06-01 23:07:...|websiteB|ljzx.eiuxoxqvtk@v...|1978-07-01 17:47:...|    Meghan Grant| Johnnie Cochran|      430 Green Milton Way|726 West White Ha...|                 New Jersey|                    81183|                       Alaska|     73 Cowley Avenue|2018-06-01 23:07:...|        767393|\n",
      "|2018-06-01 23:09:...|websiteZ|  phbr732@xcbcxp.org|1981-02-06 19:58:...|     Jamie Ayala|Jerry Mc Connell|       65 Milton Boulevard|42 South Green Fa...|                   Kentucky|                    37333|                      Montana|           42 New St.|2018-06-01 23:09:...|        193639|\n",
      "|2018-06-01 23:09:...|websiteX|naor.obmfwe@skiwj...|                null|    Eugene Velez|    Jose Wiggins|      889 West First St...|74 North Rocky Mi...|                      Idaho|                    73982|                     Arkansas| 389 South Green C...|2018-06-01 23:09:...|        966361|\n",
      "|2018-06-01 23:09:...|websiteG|  vxdue01@dkfvpz.net|1972-06-18 10:11:...|     Daphne Wade|  Jeannie Duarte|         952 Clarendon St.|853 White New Avenue|                   Michigan|                     1018|                   New Jersey|       83 Fabien Road|2018-06-01 23:09:...|         77581|\n",
      "+--------------------+--------+--------------------+--------------------+----------------+----------------+--------------------------+--------------------+---------------------------+-------------------------+-----------------------------+---------------------+--------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b76142f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (1000214, 14)\n",
      "Records with empty timestamp value: 0\n",
      "Records with empty site value: 10146\n",
      "Records with empty customeremail value: 9984\n",
      "Records with empty familyname value: 10063\n",
      "Records with empty givennames value: 10034\n",
      "Records with empty customernumber value: 1\n",
      "Records with empty dateofbirth value: 10112\n",
      "Records with invalid email values: 595351\n",
      "Records with duplicate customernumber value: 214\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataframe shape: ({df.count()}, {len(df.columns)})\")\n",
    "not_null_cols = ['timestamp', 'site', 'customeremail', 'familyname',\n",
    "                 'givennames', 'customernumber', 'dateofbirth']\n",
    "for c in not_null_cols:\n",
    "    print(f\"Records with empty {c} value: {df.where(col(c).isNull()).count()}\")\n",
    "\n",
    "invalid_email_records = df.select('customeremail').where(~col('customeremail').rlike('^[a-z0-9]+[\\._]?[a-z0-9]+[@]\\w+[.]\\w{2,3}$')).count()\n",
    "print(f\"Records with invalid email values: {invalid_email_records}\")\n",
    "print(f\"Records with duplicate customernumber value: {df.select('customernumber').count() - df.select('customernumber').drop_duplicates().count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59950cb8",
   "metadata": {},
   "source": [
    "### Instant games data overview:\n",
    "\n",
    "Import the data and show the first 10 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1abb8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(instantgames_file, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d6c85f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------+--------+--------------+--------------------+-----------------+----------+-------------------+----------------+-------------+\n",
      "|           timestamp| sitetid|customernumber|currency|aggregationkey|            gamename|highfrequencygame|priceineur|           feeineur|ticketexternalid|winningsineur|\n",
      "+--------------------+--------+--------------+--------+--------------+--------------------+-----------------+----------+-------------------+----------------+-------------+\n",
      "|2018-11-13 06:30:...|websiteH|        667124|     eur|          0716|  gslsngoldenesieben|             null|       2.0|0.40000000000000002|            GOV7|         null|\n",
      "|2019-01-17 00:55:...|websiteZ|        666294|     eur|          0148|             Nikolos|             null|       3.0|0.80000000000000004|        HUC49302|         null|\n",
      "|2019-11-06 22:32:...|websiteD|        667578|     eur|          0724|  gslsngoldhoernchen|             null|       2.0|0.40000000000000002|            SOC5|         null|\n",
      "|2019-08-12 08:08:...|websiteZ|        666791|     eur|          0727|gslnwfettefivehun...|             null|       1.5|0.29999999999999999|           LIW65|         null|\n",
      "|2019-04-09 13:01:...|websiteZ|        666830|     eur|          0325|   gslsnheissesieben|             null|       2.0|0.40000000000000002|             PAG|         null|\n",
      "|2019-12-27 08:28:...|websiteG|        664510|     eur|          0120|           DickeHose|             null|       0.5|0.10000000000000001|            LAK2|         null|\n",
      "|2019-12-13 17:30:...|websiteX|        667387|     eur|          0716|  gslsngoldenesieben|             null|       2.0|0.40000000000000002|           YOJ02|         null|\n",
      "|2018-08-14 12:10:...|websiteE|        665380|     eur|          0724|  gslsngoldhoernchen|             null|       2.0|0.40000000000000002|            null|         null|\n",
      "|2019-11-03 15:40:...|websiteD|        665106|     eur|          0129|          fettebeute|             null|       0.5|0.10000000000000001|           REL33|         null|\n",
      "|2019-02-01 08:45:...|websiteG|        667173|     eur|          0131|          stinkreich|             null|       3.5|                1.0|          LOX704|         null|\n",
      "+--------------------+--------+--------------+--------+--------------+--------------------+-----------------+----------+-------------------+----------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8593d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (5102610, 11)\n",
      "Records with empty timestamp value: 0\n",
      "Records with empty sitetid value: 249097\n",
      "Records with empty customernumber value: 100216\n",
      "Records with empty gamename value: 199006\n",
      "Records with empty priceineur value: 199006\n",
      "Records with empty feeineur value: 199006\n",
      "Records with empty ticketexternalid value: 50600\n",
      "Records with negative priceineur value: 0\n",
      "Records with negative feeineur value: 0\n",
      "Records with negative winningsineur value: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataframe shape: ({df.count()}, {len(df.columns)})\")\n",
    "not_null_cols =  ['timestamp', 'sitetid', 'customernumber', 'gamename',\n",
    "                  'priceineur', 'feeineur', 'ticketexternalid']\n",
    "for c in not_null_cols:\n",
    "    print(f\"Records with empty {c} value: {df.where(col(c).isNull()).count()}\")\n",
    "\n",
    "not_neg_cols = ['priceineur', 'feeineur', 'winningsineur']\n",
    "for c in not_neg_cols:\n",
    "    print(f\"Records with negative {c} value: {df.where(col(c) < 0).count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c475aade",
   "metadata": {},
   "source": [
    "### Lottery games data overview:\n",
    "\n",
    "Import the data and show the first 10 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b391ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(lotterygames_file, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f7ed491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+--------------+--------+-------------+----------------+------------+---------------+--------------------+--------+--------+--------------------+\n",
      "|timestampunix|    site|customernumber|currency|amountincents|feeamountincents|        game|orderidentifier|paymentamountincents|ticketid|betindex|            discount|\n",
      "+-------------+--------+--------------+--------+-------------+----------------+------------+---------------+--------------------+--------+--------+--------------------+\n",
      "|   1558931809|websiteA|        132197|     eur|          600|              60|       LOTTO|        ZAH1258|                null|   34771|      12|{\"discountInMinor...|\n",
      "|   1544542681|websiteE|        131323|     eur|          750|              75| CASH_4_LIFE|        HAC4670|                null|   93454|       3|{\"discountInMinor...|\n",
      "|   1577412253|websiteH|        130749|     eur|          750|              75| CASH_4_LIFE|        DEJ1680|                null|   02341|       3|{\"discountInMinor...|\n",
      "|   1529599256|websiteA|        132175|     eur|          100|              10|       LOTTO|        ZIN9206|                null|   83972|       2|{\"discountInMinor...|\n",
      "|   1541317416|websiteZ|        132578|     eur|          600|              60|       LOTTO|            XUM|                null|   97975|      12|{\"discountInMinor...|\n",
      "|   1556439002|websiteA|        133014|     eur|          350|             175|    UK_LOTTO|          RAS23|                null|   25674|       1|{\"discountInMinor...|\n",
      "|   1562260630|websiteF|        132637|     eur|          600|             200|        KENO|           YUQ7|                null|   38389|       2|{\"discountInMinor...|\n",
      "|   1566127658|websiteF|        132767|     eur|         2400|             400|    EML_PLUS|            LEN|                null|   28975|       6|{\"discountInMinor...|\n",
      "|   1546253740|websiteX|        132437|     eur|         3150|             450|US_POWERBALL|        HOC3377|                null|   83641|       7|{\"discountInMinor...|\n",
      "|         null|    null|        132013|    null|         null|            null|        null|         HUW260|                null|   44187|      14|{\"discountInMinor...|\n",
      "+-------------+--------+--------------+--------+-------------+----------------+------------+---------------+--------------------+--------+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4392edf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (5099164, 12)\n",
      "Records with empty timestampunix value: 248768\n",
      "Records with empty site value: 201642\n",
      "Records with empty customernumber value: 100844\n",
      "Records with empty amountincents value: 199937\n",
      "Records with empty feeamountincents value: 199937\n",
      "Records with empty game value: 50947\n",
      "Records with empty orderidentifier value: 50795\n",
      "Records with empty ticketid value: 50980\n",
      "Records with negative amountincents value: 0\n",
      "Records with negative feeamountincents value: 0\n",
      "Records with negative paymentamountincents value: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataframe shape: ({df.count()}, {len(df.columns)})\")\n",
    "not_null_cols =  ['timestampunix', 'site', 'customernumber', 'amountincents',\n",
    "                  'feeamountincents', 'game', 'orderidentifier', 'ticketid']\n",
    "for c in not_null_cols:\n",
    "    print(f\"Records with empty {c} value: {df.where(col(c).isNull()).count()}\")\n",
    "\n",
    "not_neg_cols = ['amountincents', 'feeamountincents', 'paymentamountincents']\n",
    "for c in not_neg_cols:\n",
    "    print(f\"Records with negative {c} value: {df.where(col(c) < 0).count()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
